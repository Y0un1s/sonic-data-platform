{"cells":[{"cell_type":"code","source":["# =========================================================\n","# CELL 1: SETUP & AUTH (OFFICIAL + RECCOBEATS SIMPLE)\n","# =========================================================\n","import json\n","import time\n","import requests\n","import base64\n","import os\n","from datetime import datetime\n","from notebookutils import mssparkutils\n","\n","# PATHS\n","BRONZE_BASE_PATH = \"Files/bronze/spotify\"\n","SILVER_BASE_PATH = \"Files/silver/spotify\"\n","RUN_DATE_STR = datetime.now().strftime(\"%Y-%m-%d\")\n","\n","# ‚ö†Ô∏è IMPORTANT:\n","# Secrets are hard-coded here TEMPORARILY for local/testing purposes only.\n","# In production, all secrets MUST be retrieved securely from Azure Key Vault\n","# This approach was used only because the Azure Key Vault subscription\n","# was temporarily suspended at development time.\n","\n","# SPOTIFY AUTH\n","try:\n","    SPOTIFY_CLIENT_ID = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n","    SPOTIFY_CLIENT_SECRET = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n","    print(\"‚úÖ Loaded Spotify App Credentials.\")\n","except:\n","    SPOTIFY_CLIENT_ID = None\n","    SPOTIFY_CLIENT_SECRET = None\n","    print(\"‚ö†Ô∏è Could not load Spotify credentials.\")\n","\n","def get_app_token():\n","    if not SPOTIFY_CLIENT_ID or not SPOTIFY_CLIENT_SECRET:\n","        raise RuntimeError(\"Missing Spotify credentials.\")\n","    token = f\"{SPOTIFY_CLIENT_ID}:{SPOTIFY_CLIENT_SECRET}\"\n","    b64 = base64.b64encode(token.encode()).decode()\n","    resp = requests.post(\n","        \"https://accounts.spotify.com/api/token\",\n","        headers={\"Authorization\": f\"Basic {b64}\"},\n","        data={\"grant_type\": \"client_credentials\"},\n","        timeout=10\n","    )\n","    if not resp.ok:\n","        raise RuntimeError(resp.text)\n","    return resp.json()[\"access_token\"]\n","\n","# RECCOBEATS (NO AUTH REQUIRED)\n","RECCOBEATS_BASE_URL = \"https://api.reccobeats.com\"\n","\n","def get_reccobeats_headers():\n","    return {\"Accept\": \"application/json\"}\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"624ab789-1c7c-4a89-a2b6-0e287b7d0f4a","normalized_state":"finished","queued_time":"2025-11-29T10:15:14.5238483Z","session_start_time":"2025-11-29T10:15:14.524807Z","execution_start_time":"2025-11-29T10:15:32.1427069Z","execution_finish_time":"2025-11-29T10:15:32.6520791Z","parent_msg_id":"3bfd3a36-5e17-4c1c-9807-47c179807296"},"text/plain":"StatementMeta(, 624ab789-1c7c-4a89-a2b6-0e287b7d0f4a, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Loaded Spotify App Credentials.\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f5168982-0cb6-4985-8c37-cca29481f829"},{"cell_type":"code","source":["# =========================================================\n","# CELL 2: MASTER DATA MANAGER (READ/WRITE JSONL)\n","# =========================================================\n","\n","def get_silver_path(category, user_folder):\n","    return f\"/lakehouse/default/{SILVER_BASE_PATH}/{user_folder}/{category}.json\"\n","\n","def load_processed_ids(category, user_folder):\n","    \"\"\"Return set of IDs already stored in the master file.\"\"\"\n","    path = get_silver_path(category, user_folder)\n","    ids = set()\n","    if os.path.exists(path):\n","        try:\n","            with open(path, \"r\", encoding=\"utf-8\") as f:\n","                for line in f:\n","                    obj = json.loads(line)\n","                    if obj.get(\"id\"):\n","                        ids.add(obj[\"id\"])\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error reading {category}: {e}\")\n","    return ids\n","\n","def append_to_master(new_items, category, user_folder):\n","    if not new_items:\n","        print(f\"   ‚ÑπÔ∏è No new {category} to append.\")\n","        return 0\n","\n","    path = get_silver_path(category, user_folder)\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","\n","    count = 0\n","    with open(path, \"a\", encoding=\"utf-8\") as f:\n","        for obj in new_items:\n","            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n","            count += 1\n","\n","    print(f\"   üíæ Appended {count} ‚Üí {category}\")\n","    return count\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"624ab789-1c7c-4a89-a2b6-0e287b7d0f4a","normalized_state":"finished","queued_time":"2025-11-29T10:15:35.361001Z","session_start_time":null,"execution_start_time":"2025-11-29T10:15:35.3622205Z","execution_finish_time":"2025-11-29T10:15:35.8181539Z","parent_msg_id":"de105126-6a4a-45a2-ae48-026157bd195d"},"text/plain":"StatementMeta(, 624ab789-1c7c-4a89-a2b6-0e287b7d0f4a, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"baecd10d-08d1-4735-96e1-7908f3d996ca"},{"cell_type":"code","source":["# =========================================================\n","# CELL 3: HARVEST IDS FROM BRONZE (ALL DATES)\n","# =========================================================\n","import os\n","\n","def harvest_ids_dynamic(folder_name):\n","    all_track_ids = set()\n","    all_artist_ids = set()\n","    top_artist_ids = set()\n","\n","    base_path = f\"/lakehouse/default/{BRONZE_BASE_PATH}/{folder_name}\"\n","    if not os.path.exists(base_path):\n","        print(f\"‚ö†Ô∏è Missing folder: {base_path}\")\n","        return [], [], []\n","\n","    # List category folders\n","    try:\n","        categories = [c.name for c in os.scandir(base_path) if c.is_dir()]\n","    except Exception as e:\n","        print(\"‚ö†Ô∏è Unable to scan categories:\", e)\n","        return [], [], []\n","\n","    print(f\"   üîé Scanning {len(categories)} category folders...\")\n","\n","    # Loop each category (saved_tracks, playlists, recently_played, etc.)\n","    for cat in categories:\n","        cat_path = f\"{base_path}/{cat}\"\n","\n","        # List all date folders inside category\n","        try:\n","            dates = [d.name for d in os.scandir(cat_path) if d.is_dir()]\n","        except:\n","            continue\n","\n","        # Loop each date inside this category\n","        for date in dates:\n","            file_path = f\"{cat_path}/{date}/data.json\"\n","            if not os.path.exists(file_path):\n","                continue\n","\n","            # Load JSON safely\n","            try:\n","                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                    data = json.load(f)\n","                payload = data.get(\"payload\", [])\n","            except:\n","                continue\n","\n","            # Flatten payload ‚Üí extract list of items\n","            items = []\n","            if isinstance(payload, list):\n","                for page in payload:\n","                    if isinstance(page, dict):\n","                        items.extend(page.get(\"items\", []))\n","            elif isinstance(payload, dict):\n","                # might be items or artists.items\n","                if \"items\" in payload:\n","                    items = payload.get(\"items\", [])\n","                elif \"artists\" in payload and isinstance(payload[\"artists\"], dict):\n","                    items = payload[\"artists\"].get(\"items\", [])\n","\n","            # ============================\n","            # EXTRACT TRACKS & ARTISTS\n","            # ============================\n","            for item in items:\n","                if not isinstance(item, dict):\n","                    continue\n","\n","                # ----------------------------------------------------------\n","                # A) Saved Albums (album structure with embedded tracks)\n","                # ----------------------------------------------------------\n","                if \"album\" in item and \"added_at\" in item:\n","                    album = item.get(\"album\", {})\n","                    tracks_src = album.get(\"tracks\", {})\n","\n","                    album_tracks = (\n","                        tracks_src.get(\"items\", [])\n","                        if isinstance(tracks_src, dict)\n","                        else []\n","                    )\n","\n","                    for t in album_tracks:\n","                        if isinstance(t, dict) and t.get(\"id\"):\n","                            all_track_ids.add(t[\"id\"])\n","                            for a in t.get(\"artists\", []):\n","                                if isinstance(a, dict) and a.get(\"id\"):\n","                                    all_artist_ids.add(a[\"id\"])\n","                    continue\n","\n","                # ----------------------------------------------------------\n","                # B) Track Wrapper (playlist item, recently played)\n","                # ----------------------------------------------------------\n","                if \"track\" in item:\n","                    t = item.get(\"track\")\n","                    if isinstance(t, dict) and t.get(\"id\"):\n","                        all_track_ids.add(t[\"id\"])\n","                        for a in t.get(\"artists\", []):\n","                            if isinstance(a, dict) and a.get(\"id\"):\n","                                all_artist_ids.add(a[\"id\"])\n","                    continue\n","\n","                # ----------------------------------------------------------\n","                # C) Direct Track Object (raw Spotify object)\n","                # ----------------------------------------------------------\n","                if item.get(\"type\") == \"track\" and item.get(\"id\"):\n","                    all_track_ids.add(item[\"id\"])\n","                    for a in item.get(\"artists\", []):\n","                        if isinstance(a, dict) and a.get(\"id\"):\n","                            all_artist_ids.add(a[\"id\"])\n","                    continue\n","\n","                # ----------------------------------------------------------\n","                # D) Direct Artist Object\n","                # ----------------------------------------------------------\n","                if item.get(\"type\") == \"artist\" and item.get(\"id\"):\n","                    all_artist_ids.add(item[\"id\"])\n","                    if \"top_artists\" in cat:\n","                        top_artist_ids.add(item[\"id\"])\n","                    continue\n","\n","    # return unique lists\n","    return list(all_track_ids), list(all_artist_ids), list(top_artist_ids)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"624ab789-1c7c-4a89-a2b6-0e287b7d0f4a","normalized_state":"finished","queued_time":"2025-11-29T10:15:39.9097609Z","session_start_time":null,"execution_start_time":"2025-11-29T10:15:39.9111182Z","execution_finish_time":"2025-11-29T10:15:40.1984125Z","parent_msg_id":"4ada3be1-ad6a-42cb-89ea-ba67af683e97"},"text/plain":"StatementMeta(, 624ab789-1c7c-4a89-a2b6-0e287b7d0f4a, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bedca3ed-ab8f-4616-928b-22fe73297523"},{"cell_type":"code","source":["# =========================================================\n","# CELL 4 (UPDATED): FETCH RECCOBEATS METADATA WITH SPOTIFY ID\n","# =========================================================\n","\n","def discover_users_from_onelake():\n","    \"\"\"\n","    Scans Files/bronze/spotify for user folders.\n","    Each subfolder represents a user.\n","    Returns list of:\n","      { \"folder_name\": <folder>, \"display_name\": <folder> }\n","    \"\"\"\n","    base_path = f\"/lakehouse/default/{BRONZE_BASE_PATH}\"\n","    users = []\n","\n","    if not os.path.exists(base_path):\n","        print(f\"‚ö†Ô∏è User base folder not found: {base_path}\")\n","        return []\n","\n","    try:\n","        for entry in os.scandir(base_path):\n","            if entry.is_dir():\n","                folder = entry.name\n","                users.append({\n","                    \"folder_name\": folder,\n","                    \"display_name\": folder\n","                })\n","    except Exception as e:\n","        print(f\"‚ùå Error scanning OneLake users: {repr(e)}\")\n","        return []\n","\n","    print(f\"üë• Found {len(users)} user folders in OneLake.\")\n","    return users\n","\n","def fetch_reccobeats_tracks(spotify_track_ids):\n","    \"\"\"\n","    Calls: GET /v1/track?ids=<list>\n","    Saves BOTH:\n","      - spotify_id   (from your Bronze raw data)\n","      - recco_id     (ReccoBeats-generated ID)\n","    \"\"\"\n","    base_url = f\"{RECCOBEATS_BASE_URL}/v1/track\"\n","    headers = get_reccobeats_headers()\n","\n","    results = []\n","\n","    # Process batches of 40 (API max)\n","    for i in range(0, len(spotify_track_ids), 40):\n","        batch = spotify_track_ids[i:i+40]\n","\n","        try:\n","            resp = requests.get(\n","                base_url,\n","                headers=headers,\n","                params={\"ids\": batch},\n","                timeout=10\n","            )\n","\n","            if resp.status_code == 200:\n","                content = resp.json().get(\"content\", [])\n","                for idx, item in enumerate(content):\n","                    if not isinstance(item, dict):\n","                        continue\n","\n","                    rec_id = item.get(\"id\")\n","                    sp_id  = batch[idx]  # spotify ID from input\n","\n","                    # Inject spotify_id into record\n","                    item[\"spotify_id\"] = sp_id\n","                    item[\"recco_id\"]   = rec_id\n","\n","                    results.append(item)\n","            else:\n","                print(f\"‚ö†Ô∏è Error {resp.status_code} on batch: {resp.text[:200]}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Exception fetching batch: {repr(e)}\")\n","\n","        time.sleep(0.15)\n","\n","    return results\n","\n","def fetch_artist_details(access_token, artist_ids):\n","    url = \"https://api.spotify.com/v1/artists\"\n","    results = []\n","\n","    print(f\"üé® Fetching {len(artist_ids)} artists from Spotify API...\")\n","\n","    for i in range(0, len(artist_ids), 50):\n","        batch = artist_ids[i:i+50]\n","\n","        resp = requests.get(\n","            url,\n","            params={\"ids\": \",\".join(batch)},\n","            headers={\"Authorization\": f\"Bearer {access_token}\"},\n","            timeout=10\n","        )\n","\n","        if resp.status_code == 200:\n","            results.extend(resp.json().get(\"artists\", []))\n","\n","        elif resp.status_code == 429:\n","            wait = int(resp.headers.get(\"Retry-After\", 5))\n","            print(f\"‚è≥ Rate-limit hit. Waiting {wait}s...\")\n","            time.sleep(wait)\n","            continue\n","\n","        else:\n","            print(f\"‚ö†Ô∏è Error {resp.status_code}: {resp.text[:200]}\")\n","\n","        time.sleep(0.1)\n","\n","    return results"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"624ab789-1c7c-4a89-a2b6-0e287b7d0f4a","normalized_state":"finished","queued_time":"2025-11-29T10:15:44.2580502Z","session_start_time":null,"execution_start_time":"2025-11-29T10:15:44.2593328Z","execution_finish_time":"2025-11-29T10:15:44.7652977Z","parent_msg_id":"640c77e9-a08d-4b9c-ade7-d12790f722a8"},"text/plain":"StatementMeta(, 624ab789-1c7c-4a89-a2b6-0e287b7d0f4a, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7d59dbb2-4d70-42ae-8335-34779b9ebd58"},{"cell_type":"code","source":["# =========================================================\n","# CELL 5 (UPDATED): INGEST TRACK METADATA + ARTISTS\n","# =========================================================\n","\n","print(\"üîë Getting Spotify Token...\")\n","app_token = get_app_token()\n","\n","print(\"üìÇ Discovering users...\")\n","users = discover_users_from_onelake()\n","\n","TEST_LIMIT = None\n","\n","for user in users:\n","    fname = user[\"folder_name\"]\n","    uname = user[\"display_name\"]\n","\n","    print(f\"\\n=== Processing {uname} ===\")\n","\n","    # ----------------------------------------\n","    # 1) HARVEST BRONZE\n","    # ----------------------------------------\n","    raw_tracks, raw_artists, _ = harvest_ids_dynamic(fname)\n","    raw_tracks = list(set(raw_tracks))\n","    raw_artists = list(set(raw_artists))\n","\n","    print(f\"   üîç {len(raw_tracks)} Spotify tracks harvested.\")\n","    print(f\"   üé® {len(raw_artists)} Spotify artists harvested.\")\n","\n","    # ----------------------------------------\n","    # 2) LOAD EXISTING (using spotify_id, not recco_id)\n","    # ----------------------------------------\n","    path_tracks = get_silver_path(\"master_reccobeats_tracks\", fname)\n","\n","    existing_spotify_ids = set()\n","    if os.path.exists(path_tracks):\n","        with open(path_tracks, \"r\", encoding=\"utf-8\") as f:\n","            for line in f:\n","                try:\n","                    obj = json.loads(line)\n","                    if obj.get(\"spotify_id\"):\n","                        existing_spotify_ids.add(obj[\"spotify_id\"])\n","                except:\n","                    pass\n","\n","    # Compute delta (NEW tracks only)\n","    new_track_ids = [tid for tid in raw_tracks if tid not in existing_spotify_ids]\n","\n","    print(f\"   üöÄ {len(new_track_ids)} new tracks to fetch.\")\n","\n","    if TEST_LIMIT:\n","        new_track_ids = new_track_ids[:TEST_LIMIT]\n","        print(f\"   ‚ö†Ô∏è TEST MODE: limiting to {len(new_track_ids)} tracks\")\n","\n","    # ----------------------------------------\n","    # 3) FETCH RECCOBEATS METADATA\n","    # ----------------------------------------\n","    if new_track_ids:\n","        track_records = fetch_reccobeats_tracks(new_track_ids)\n","        appended = append_to_master(track_records, \"master_reccobeats_tracks\", fname)\n","        print(f\"   ‚úÖ Saved metadata for {appended} tracks\")\n","    else:\n","        print(\"   ‚ÑπÔ∏è No new tracks to fetch.\")\n","\n","    # ----------------------------------------\n","    # 4) ARTIST INGESTION (unchanged)\n","    # ----------------------------------------\n","    existing_artists = load_processed_ids(\"master_artists\", fname)\n","    new_artist_ids = [aid for aid in raw_artists if aid not in existing_artists]\n","\n","    print(f\"   üé® NEW artists: {len(new_artist_ids)}\")\n","\n","    if TEST_LIMIT:\n","        new_artist_ids = new_artist_ids[:TEST_LIMIT]\n","\n","    if new_artist_ids:\n","        artist_data = fetch_artist_details(app_token, new_artist_ids)\n","        appended_art = append_to_master(artist_data, \"master_artists\", fname)\n","        print(f\"   ‚úÖ Artist Details Saved: {appended_art}\")\n","    else:\n","        print(\"   ‚ÑπÔ∏è No new artists to fetch.\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d2430a0-ec91-4123-97a5-48340c27c4a2"},{"cell_type":"code","source":["# =========================================================\n","# CELL 6: FETCH AUDIO FEATURES (STEP 4)\n","# =========================================================\n","\n","def fetch_reccobeats_audio_features(rid):\n","    url = f\"{RECCOBEATS_BASE_URL}/v1/track/{rid}/audio-features\"\n","    headers = get_reccobeats_headers()\n","\n","    try:\n","        resp = requests.get(url, headers=headers, timeout=8)\n","        if resp.status_code == 200:\n","            data = resp.json()\n","            data[\"id\"] = data.get(\"id\", rid)\n","            return data\n","        else:\n","            print(f\"‚ö†Ô∏è {resp.status_code} on feature fetch for {rid}\")\n","            return None\n","    except Exception as e:\n","        print(f\"‚ùå Error fetching features for {rid}: {repr(e)}\")\n","        return None\n","\n","\n","# ========= CONFIG =========\n","TEST_FEATURE_LIMIT = None\n","BATCH_SIZE = 100  # adjust for speed vs stability\n","\n","\n","print(\"\\nüîç Starting batched audio-feature ingestion...\\n\")\n","\n","for user in users:\n","    fname = user[\"folder_name\"]\n","    uname = user[\"display_name\"]\n","\n","    print(f\"\\n=== Features for {uname} ===\")\n","\n","    # Load track metadata\n","    path = get_silver_path(\"master_reccobeats_tracks\", fname)\n","    if not os.path.exists(path):\n","        print(\"   ‚ÑπÔ∏è No track metadata found.\")\n","        continue\n","\n","    # Collect all ReccoBeats track IDs\n","    recc_ids = []\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            try:\n","                obj = json.loads(line)\n","                if obj.get(\"id\"):\n","                    recc_ids.append(obj[\"id\"])\n","            except:\n","                continue\n","\n","    recc_ids = list(set(recc_ids))\n","    print(f\"   üéØ {len(recc_ids)} ReccoBeats track IDs found\")\n","\n","    # Load existing feature rows\n","    existing_feats = load_processed_ids(\"master_reccobeats_features\", fname)\n","    new_ids = [rid for rid in recc_ids if rid not in existing_feats]\n","\n","    print(f\"   üöÄ {len(new_ids)} tracks still missing audio features\")\n","\n","    if TEST_FEATURE_LIMIT is not None:\n","        new_ids = new_ids[:TEST_FEATURE_LIMIT]\n","        print(f\"   ‚ö†Ô∏è TEST MODE: limiting to {len(new_ids)} tracks\")\n","\n","    # ================================\n","    # BATCHED INGESTION LOOP (LIMITED TO 100 BATCHES)\n","    # ================================\n","    MAX_BATCHES = 100\n","    batched_features = []\n","\n","    total_batches = (len(new_ids) + BATCH_SIZE - 1) // BATCH_SIZE\n","    batches_to_run = min(total_batches, MAX_BATCHES)\n","\n","    for b in range(batches_to_run):\n","        batch = new_ids[b * BATCH_SIZE : (b + 1) * BATCH_SIZE]\n","        print(f\"   üì¶ Batch {b+1}/{batches_to_run} ‚Äî {len(batch)} tracks\")\n","\n","        batch_features = []\n","\n","        # fetch features for each track in this batch\n","        for rid in batch:\n","            feat = fetch_reccobeats_audio_features(rid)\n","            if not feat:\n","                continue\n","            batch_features.append(feat)\n","            time.sleep(0.08)\n","        appended = append_to_master(batch_features, \"master_reccobeats_features\", fname)\n","        print(f\"     üíæ Saved {appended} feature records (batch {b+1})\")\n","\n","print(\"\\nüéâ DONE ‚Äî Batched Audio-Features Pipeline Complete\\n\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e0741fef-c737-448b-af9a-471cd4be1f28"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2"}],"default_lakehouse":"e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2","default_lakehouse_name":"sonic_lakehouse","default_lakehouse_workspace_id":"93da16a5-3c33-440e-bbec-66866bce621b"}}},"nbformat":4,"nbformat_minor":5}