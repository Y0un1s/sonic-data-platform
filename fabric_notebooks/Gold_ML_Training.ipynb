{"cells":[{"cell_type":"code","source":["%pip install annoy\n","%pip install lightgbm scikit-learn\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[3,4,5,6,7,8],"state":"finished","livy_statement_state":"available","session_id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","normalized_state":"finished","queued_time":"2025-11-25T06:37:51.1992685Z","session_start_time":"2025-11-25T06:37:51.1995732Z","execution_start_time":"2025-11-25T06:38:06.1568555Z","execution_finish_time":"2025-11-25T06:38:47.4168691Z","parent_msg_id":"76156263-bb8c-4926-ba22-5ac81171523c"},"text/plain":"StatementMeta(, bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting annoy\n  Downloading annoy-1.17.3.tar.gz (647 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25hBuilding wheels for collected packages: annoy\n  Building wheel for annoy (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-linux_x86_64.whl size=77476 sha256=9b999553dc7756462a5f1452bfcbca9751359a6a641885405b017fa1d503bcdb\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/33/e5/58/0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\nSuccessfully built annoy\nInstalling collected packages: annoy\nSuccessfully installed annoy-1.17.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: lightgbm in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (4.3.0)\nRequirement already satisfied: scikit-learn in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (1.2.2)\nRequirement already satisfied: numpy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from lightgbm) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"336e4ae3-dd31-4750-97dd-10b391f9d7c7"},{"cell_type":"code","source":["# ============================================\n","# CELL 1 â€” CONFIG & IMPORTS\n","# ============================================\n","from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import col\n","from pyspark.sql import Row\n","import numpy as np\n","\n","# Table / path constants\n","GOLD_LABEL_TABLE    = \"gold_ml_training_set\"\n","USER_EMB_TABLE      = \"gold_two_tower_user_emb\"\n","ITEM_EMB_TABLE      = \"gold_two_tower_item_emb\"\n","INTERACTIONS_TABLE  = \"gold_user_interactions\"\n","CATALOG_TABLE       = \"gold_ml_catalog\"\n","MODEL_PATH          = \"Files/models/gbt_physics_baseline\"\n","\n","# Audio feature columns\n","AUDIO_FEATURES = [\n","    \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\",\n","    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"\n","]\n","\n","print(\"âœ… Config loaded.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","normalized_state":"finished","queued_time":"2025-11-25T06:44:54.4301024Z","session_start_time":null,"execution_start_time":"2025-11-25T06:44:54.4313103Z","execution_finish_time":"2025-11-25T06:44:54.81874Z","parent_msg_id":"8f52a624-5b0c-4b0f-a973-167797f634dd"},"text/plain":"StatementMeta(, bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Config loaded.\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb3c6fdc-ecc7-4c7e-a723-74092186f652"},{"cell_type":"code","source":["# ============================================\n","# BUILD UNIFIED AUDIO + METADATA CATALOG\n","# gold_ml_catalog\n","# ============================================\n","\n","from pyspark.sql.functions import col\n","\n","audio_raw  = spark.table(\"silver_audio_features_raw\")\n","tracks_raw = spark.table(\"silver_tracks_raw\")\n","ml_public  = spark.table(\"silver_ml_training_set\")\n","\n","final_cols = [\"spotify_id\", \"track_name\", \"artist_name\"] + AUDIO_FEATURES\n","\n","# --------------------------------------------\n","# 1) User-side (private) high-quality metadata\n","# --------------------------------------------\n","df_user = (\n","    audio_raw.join(tracks_raw, \"spotify_id\")\n","        .withColumnRenamed(\"artist_recco_id\", \"artist_id\")\n","        .select(final_cols)\n",")\n","\n","# --------------------------------------------\n","# 2) Public ML tracks (fallback metadata)\n","# --------------------------------------------\n","df_public = (\n","    ml_public\n","        .withColumn(\"artist_name\", col(\"artists\"))\n","        .select(final_cols)\n",")\n","\n","# Only include public tracks that are NOT in df_user\n","df_public_new = df_public.join(df_user, \"spotify_id\", \"left_anti\")\n","\n","# --------------------------------------------\n","# 3) Build unified catalog\n","# --------------------------------------------\n","catalog_unified = df_user.unionByName(df_public_new)\n","\n","# Remove rows missing audio features\n","catalog_clean = catalog_unified.na.drop(subset=AUDIO_FEATURES)\n","\n","# Save\n","catalog_clean.write.mode(\"overwrite\").format(\"delta\").saveAsTable(CATALOG_TABLE)\n","\n","total = spark.table(CATALOG_TABLE).count()\n","print(f\"âœ… Catalog saved: {CATALOG_TABLE}\")\n","print(f\"ðŸ“Š Total songs: {total:,}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":47,"statement_ids":[47],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:49:48.3072491Z","session_start_time":null,"execution_start_time":"2025-11-25T05:49:48.3084Z","execution_finish_time":"2025-11-25T05:50:25.5269058Z","parent_msg_id":"b1826594-e410-4d1b-aeb1-54a4f19b3110"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 47, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Catalog saved: gold_ml_catalog\nðŸ“Š Total songs: 1,239,363\n"]}],"execution_count":39,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"99fa68f0-568f-40ec-9a13-61b0b23aa1a8\",\"activityId\":\"49a05bbd-c6a8-4416-a4f5-03f18f92bc70\",\"applicationId\":\"application_1764045157499_0001\",\"jobGroupId\":\"47\",\"advices\":{\"warn\":1}}"}},"id":"e7e7d5a9-9c9b-4789-a587-c3e75ed44771"},{"cell_type":"code","source":["# ============================================\n","# CELL 2 â€” BUILD INTERACTIONS TABLE (ONCE)\n","# ============================================\n","from pyspark.sql.functions import col\n","\n","recent = spark.table(\"silver_recently_played\").select(col(\"spotify_user_id\"), col(\"track_id\"))\n","saved  = spark.table(\"silver_saved_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\"))\n","playlist = spark.table(\"silver_playlist_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\"))\n","top = spark.table(\"silver_top_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\"))\n","\n","interactions = recent.union(saved).union(playlist).union(top).dropna().distinct()\n","\n","# Persist to table (overwrite)\n","interactions.write.mode(\"overwrite\").saveAsTable(INTERACTIONS_TABLE)\n","\n","print(f\"âœ… Interactions table saved: {INTERACTIONS_TABLE}\")\n","print(f\"ðŸ“¦ Rows: {interactions.count():,}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":48,"statement_ids":[48],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:50:09.7296073Z","session_start_time":null,"execution_start_time":"2025-11-25T05:50:25.5292211Z","execution_finish_time":"2025-11-25T05:51:24.4447605Z","parent_msg_id":"866898c8-7580-409c-a99d-b98cd9ba3376"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 48, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Interactions table saved: gold_user_interactions\nðŸ“¦ Rows: 31,099\n"]}],"execution_count":40,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad1790d3-1db8-433a-9a30-140252cad39d"},{"cell_type":"code","source":["# ============================================\n","# CELL 3 â€” INDEX USERS & ITEMS\n","# ============================================\n","from pyspark.sql.functions import row_number\n","\n","inter = spark.table(INTERACTIONS_TABLE).select(\"spotify_user_id\", \"track_id\").distinct()\n","\n","# User index\n","w_user = Window.orderBy(\"spotify_user_id\")\n","user_index = (\n","    inter.select(\"spotify_user_id\").distinct()\n","         .withColumn(\"user_idx\", row_number().over(w_user) - 1)\n",")\n","\n","# Item index\n","w_item = Window.orderBy(\"track_id\")\n","item_index = (\n","    inter.select(\"track_id\").distinct()\n","         .withColumn(\"item_idx\", row_number().over(w_item) - 1)\n",")\n","\n","num_users = user_index.count()\n","num_items = item_index.count()\n","\n","print(f\"ðŸ‘¥ Users: {num_users:,}\")\n","print(f\"ðŸŽµ Items: {num_items:,}\")\n","\n","indexed = (\n","    inter.join(user_index, \"spotify_user_id\")\n","         .join(item_index, \"track_id\")\n","         .select(\"spotify_user_id\",\"track_id\",\"user_idx\",\"item_idx\")\n",")\n","\n","indexed.cache()\n","print(f\"ðŸ“¦ Indexed interactions: {indexed.count():,}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":49,"statement_ids":[49],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:50:18.4514121Z","session_start_time":null,"execution_start_time":"2025-11-25T05:51:24.446917Z","execution_finish_time":"2025-11-25T05:51:27.0640511Z","parent_msg_id":"61070cd4-deb9-422f-91f6-0a5f3d1ecca9"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 49, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ðŸ‘¥ Users: 27\nðŸŽµ Items: 27,768\nðŸ“¦ Indexed interactions: 31,099\n"]}],"execution_count":41,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6931e8c-fa6c-4273-b2b2-b532f92520a4"},{"cell_type":"code","source":["# ============================================\n","# CELL 4 â€” TRAIN 2-TOWER MODEL (NUMPY BPR)\n","# ============================================\n","import numpy as np\n","\n","# Recompute num_users / num_items if needed\n","num_users = indexed.agg(F.max(\"user_idx\")).collect()[0][0] + 1\n","num_items = indexed.agg(F.max(\"item_idx\")).collect()[0][0] + 1\n","\n","print(f\"ðŸ‘¥ num_users = {num_users}\")\n","print(f\"ðŸŽµ num_items = {num_items}\")\n","\n","# Collect interactions (sample if too large)\n","indexed_pd = indexed.toPandas()\n","user_indices = indexed_pd[\"user_idx\"].values.astype(np.int32)\n","item_indices = indexed_pd[\"item_idx\"].values.astype(np.int32)\n","n_interactions = len(user_indices)\n","print(f\"ðŸ“¦ Interactions loaded: {n_interactions:,}\")\n","\n","# HYPERPARAMS\n","embedding_dim = 256\n","learning_rate = 0.05\n","reg_lambda = 0.001\n","num_epochs = 5\n","batch_size = 4096\n","\n","# Initialize embeddings\n","rng = np.random.default_rng(42)\n","user_emb_matrix = 0.01 * rng.standard_normal((num_users, embedding_dim), dtype=np.float32)\n","item_emb_matrix = 0.01 * rng.standard_normal((num_items, embedding_dim), dtype=np.float32)\n","\n","def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))\n","\n","# Training loop (BPR)\n","for epoch in range(1, num_epochs + 1):\n","    perm = rng.permutation(n_interactions)\n","    user_indices_sh = user_indices[perm]\n","    item_indices_sh = item_indices[perm]\n","\n","    total_loss = 0.0\n","    n_steps = 0\n","\n","    for start in range(0, n_interactions, batch_size):\n","        end = min(start + batch_size, n_interactions)\n","        u_batch = user_indices_sh[start:end]\n","        i_batch = item_indices_sh[start:end]\n","        batch_len = len(u_batch)\n","        if batch_len == 0:\n","            continue\n","\n","        j_batch = rng.integers(low=0, high=num_items, size=batch_len, dtype=np.int32)\n","\n","        u_vecs = user_emb_matrix[u_batch]\n","        i_vecs = item_emb_matrix[i_batch]\n","        j_vecs = item_emb_matrix[j_batch]\n","\n","        x_ui = np.sum(u_vecs * i_vecs, axis=1)\n","        x_uj = np.sum(u_vecs * j_vecs, axis=1)\n","        x_uij = x_ui - x_uj\n","        sig = sigmoid(x_uij)\n","        loss_vec = -np.log(sig + 1e-10)\n","        loss = np.mean(loss_vec) + reg_lambda * (\n","            np.mean(np.sum(u_vecs*u_vecs, axis=1)) +\n","            np.mean(np.sum(i_vecs*i_vecs, axis=1)) +\n","            np.mean(np.sum(j_vecs*j_vecs, axis=1))\n","        )\n","        total_loss += loss\n","        n_steps += 1\n","\n","        grad_factor = (sig - 1.0).reshape(-1, 1)\n","        grad_u = grad_factor * (i_vecs - j_vecs) + reg_lambda * u_vecs\n","        grad_i = grad_factor * u_vecs + reg_lambda * i_vecs\n","        grad_j = -grad_factor * u_vecs + reg_lambda * j_vecs\n","\n","        user_emb_matrix[u_batch]  -= learning_rate * grad_u\n","        item_emb_matrix[i_batch]  -= learning_rate * grad_i\n","        item_emb_matrix[j_batch]  -= learning_rate * grad_j\n","\n","    avg_loss = total_loss / max(1, n_steps)\n","    print(f\"ðŸ“‰ Epoch {epoch}/{num_epochs} - avg BPR loss: {avg_loss:.4f}\")\n","\n","print(\"âœ… 2-tower (NumPy BPR) training complete.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":52,"statement_ids":[52],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:54:34.5929174Z","session_start_time":null,"execution_start_time":"2025-11-25T05:54:34.5942038Z","execution_finish_time":"2025-11-25T05:54:37.6065934Z","parent_msg_id":"69441211-9107-4384-a127-9ae221272aff"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 52, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ðŸ‘¥ num_users = 27\nðŸŽµ num_items = 27768\nðŸ“¦ Interactions loaded: 31,099\nðŸ“‰ Epoch 1/5 - avg BPR loss: 0.6933\nðŸ“‰ Epoch 2/5 - avg BPR loss: 0.6930\nðŸ“‰ Epoch 3/5 - avg BPR loss: 0.6927\nðŸ“‰ Epoch 4/5 - avg BPR loss: 0.6924\nðŸ“‰ Epoch 5/5 - avg BPR loss: 0.6921\nâœ… 2-tower (NumPy BPR) training complete.\n"]}],"execution_count":44,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"87514b5c-680c-4615-b433-7e298d7ea51a"},{"cell_type":"code","source":["# ============================================\n","# CELL 5 â€” EXPORT EMBEDDINGS TO SPARK\n","# ============================================\n","from pyspark.sql.types import ArrayType, FloatType\n","from pyspark.sql import Row\n","\n","embedding_dim = user_emb_matrix.shape[1]\n","print(f\"ðŸ§  Exporting embeddings of dim {embedding_dim}\")\n","\n","# USER EMBEDDINGS\n","user_index_pd = user_index.select(\"spotify_user_id\",\"user_idx\").toPandas()\n","user_index_pd[\"vector\"] = list(user_emb_matrix[user_index_pd[\"user_idx\"].values])\n","user_rows = [\n","    Row(spotify_user_id=row.spotify_user_id,\n","        vector=[float(x) for x in row.vector])\n","    for row in user_index_pd.itertuples()\n","]\n","user_emb_spark = spark.createDataFrame(user_rows)\n","\n","# ITEM EMBEDDINGS (only for items seen in interactions)\n","item_index_pd = item_index.select(\"track_id\",\"item_idx\").toPandas()\n","item_index_pd[\"vector\"] = list(item_emb_matrix[item_index_pd[\"item_idx\"].values])\n","item_rows = [\n","    Row(spotify_id=row.track_id,\n","        vector=[float(x) for x in row.vector])\n","    for row in item_index_pd.itertuples()\n","]\n","item_emb_spark = spark.createDataFrame(item_rows)\n","\n","# TAG ITEMS AS OCEAN vs FRIENDS\n","audio_private = spark.table(\"silver_audio_features_raw\") \\\n","    .select(\"spotify_id\").distinct() \\\n","    .withColumn(\"source\", F.lit(\"friends\"))\n","\n","public_ml = spark.table(\"silver_ml_training_set\") \\\n","    .select(F.col(\"spotify_id\").cast(\"string\").alias(\"spotify_id\")) \\\n","    .distinct() \\\n","    .withColumn(\"source\", F.lit(\"ocean\"))\n","\n","source_map = audio_private.unionByName(public_ml).dropDuplicates([\"spotify_id\"])\n","\n","item_emb_spark = item_emb_spark.join(source_map, \"spotify_id\", \"left\").fillna({\"source\":\"unknown\"})\n","\n","# SAVE TO TABLES\n","user_emb_spark.write.mode(\"overwrite\").saveAsTable(USER_EMB_TABLE)\n","item_emb_spark.write.mode(\"overwrite\").saveAsTable(ITEM_EMB_TABLE)\n","\n","print(f\"âœ… User embeddings saved to:  {USER_EMB_TABLE}\")\n","print(f\"âœ… Item embeddings saved to:  {ITEM_EMB_TABLE}\")\n","print(f\"ðŸ‘¥ Users with embeddings: {user_emb_spark.count():,}\")\n","print(f\"ðŸŽµ Items with embeddings: {item_emb_spark.count():,}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":53,"statement_ids":[53],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:54:39.9963581Z","session_start_time":null,"execution_start_time":"2025-11-25T05:54:39.9974931Z","execution_finish_time":"2025-11-25T05:55:49.9859923Z","parent_msg_id":"ed5e110c-3dcc-4100-a012-7e03df2c00ab"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 53, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ðŸ§  Exporting embeddings of dim 256\nâœ… User embeddings saved to:  gold_two_tower_user_emb\nâœ… Item embeddings saved to:  gold_two_tower_item_emb\nðŸ‘¥ Users with embeddings: 27\nðŸŽµ Items with embeddings: 27,768\n"]}],"execution_count":45,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"83394e8f-2b46-43ee-8e84-169336221f04"},{"cell_type":"code","source":["# ============================================\n","# CELL 6 â€” BUILD gold_ml_training_set (POSITIVE LABELS)\n","# ============================================\n","from pyspark.sql.functions import col, lit\n","\n","rp = spark.table(\"silver_recently_played\").select(col(\"spotify_user_id\"), col(\"track_id\").alias(\"spotify_id\"))\n","saved = spark.table(\"silver_saved_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\").alias(\"spotify_id\"))\n","pl = spark.table(\"silver_playlist_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\").alias(\"spotify_id\"))\n","top = spark.table(\"silver_top_tracks\").select(col(\"spotify_user_id\"), col(\"track_id\").alias(\"spotify_id\"))\n","\n","gold = rp.union(saved).union(pl).union(top).distinct().withColumn(\"label\", lit(1))\n","gold.write.mode(\"overwrite\").saveAsTable(GOLD_LABEL_TABLE)\n","\n","print(\"âœ… Created gold_ml_training_set\")\n","print(\"ðŸ“¦ Rows:\", gold.count())\n","\n","from pyspark.sql.functions import col\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":50,"statement_ids":[50],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:51:08.1371808Z","session_start_time":null,"execution_start_time":"2025-11-25T05:51:27.0658556Z","execution_finish_time":"2025-11-25T05:52:01.9168254Z","parent_msg_id":"d5b327ad-fce8-4980-bbd2-93bd5bf451de"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 50, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Created gold_ml_training_set\nðŸ“¦ Rows: 31107\n"]}],"execution_count":42,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f2a9de27-96a1-4040-b054-276b35fb8a67"},{"cell_type":"code","source":["# ============================================\n","# CELL 7 â€” REBUILD ITEM EMBEDDINGS (HYBRID: 2-TOWER + AUDIO)\n","# ============================================\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import col, lit\n","\n","EMB_DIM = 256\n","PAD_SIZE = EMB_DIM - len(AUDIO_FEATURES)\n","print(f\"Using hybrid embeddings with dim = {EMB_DIM} (audio + padding, or 2-tower).\")\n","\n","catalog = spark.table(CATALOG_TABLE).select(\"spotify_id\", *AUDIO_FEATURES)\n","print(\"ðŸ“¦ Catalog rows:\", catalog.count())\n","\n","existing_emb = spark.table(ITEM_EMB_TABLE)\n","print(\"ðŸ“¦ Existing 2-tower item embeddings:\", existing_emb.count())\n","\n","inter = spark.table(INTERACTIONS_TABLE).select(col(\"track_id\").alias(\"spotify_id\")).distinct()\n","friends_ids = inter.withColumn(\"source\", lit(\"friends\"))\n","\n","base = (\n","    catalog\n","    .join(existing_emb.select(\"spotify_id\", \"vector\"), \"spotify_id\", \"left\")\n","    .join(friends_ids, \"spotify_id\", \"left\")\n",")\n","\n","base = base.withColumn(\n","    \"source\",\n","    F.when(col(\"source\").isNull(), lit(\"ocean\")).otherwise(col(\"source\"))\n",")\n","\n","audio_as_vec = F.array(\n","    *[col(c).cast(\"float\") for c in AUDIO_FEATURES] +\n","    [F.lit(0.0).cast(\"float\")] * PAD_SIZE\n",")\n","\n","hybrid = base.withColumn(\n","    \"vector\",\n","    F.when(col(\"vector\").isNotNull(), col(\"vector\")).otherwise(audio_as_vec)\n",")\n","\n","final_item_emb = hybrid.select(\"spotify_id\", \"vector\", \"source\")\n","print(\"âœ… Hybrid item embeddings built.\")\n","print(\"   Total rows:\", final_item_emb.count())\n","final_item_emb.groupBy(\"source\").count().show()\n","\n","final_item_emb.write.mode(\"overwrite\").saveAsTable(ITEM_EMB_TABLE)\n","print(f\"ðŸ’¾ Overwrote {ITEM_EMB_TABLE} with hybrid embeddings.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":54,"statement_ids":[54],"state":"finished","livy_statement_state":"available","session_id":"49a05bbd-c6a8-4416-a4f5-03f18f92bc70","normalized_state":"finished","queued_time":"2025-11-25T05:55:34.9530707Z","session_start_time":null,"execution_start_time":"2025-11-25T05:55:49.9881086Z","execution_finish_time":"2025-11-25T05:56:33.427469Z","parent_msg_id":"46a4b048-3a4a-43a0-a759-450b57c2c1cb"},"text/plain":"StatementMeta(, 49a05bbd-c6a8-4416-a4f5-03f18f92bc70, 54, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using hybrid embeddings with dim = 256 (audio + padding, or 2-tower).\nðŸ“¦ Catalog rows: 1239363\nðŸ“¦ Existing 2-tower item embeddings: 27768\nâœ… Hybrid item embeddings built.\n   Total rows: 1239363\n+-------+-------+\n| source|  count|\n+-------+-------+\n|friends|  23238|\n|  ocean|1216125|\n+-------+-------+\n\nðŸ’¾ Overwrote gold_two_tower_item_emb with hybrid embeddings.\n"]}],"execution_count":46,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"99fa68f0-568f-40ec-9a13-61b0b23aa1a8\",\"activityId\":\"49a05bbd-c6a8-4416-a4f5-03f18f92bc70\",\"applicationId\":\"application_1764045157499_0001\",\"jobGroupId\":\"54\",\"advices\":{\"warn\":3}}"}},"id":"0c747aa6-03cf-4f73-a715-72772d9d029a"},{"cell_type":"code","source":["from annoy import AnnoyIndex\n","import numpy as np\n","import joblib\n","import os\n","from pyspark.sql.functions import col\n","\n","# Correct persistent Fabric directory\n","ANNOY_DIR = \"/lakehouse/default/Files/annoy\"\n","os.makedirs(ANNOY_DIR, exist_ok=True)\n","\n","item_df = spark.table(ITEM_EMB_TABLE).select(\"spotify_id\", \"vector\", \"source\")\n","\n","friends_pd = item_df.filter(col(\"source\") == \"friends\").toPandas()\n","ocean_pd   = item_df.filter(col(\"source\") == \"ocean\").toPandas()\n","\n","dim = len(friends_pd.iloc[0].vector)\n","\n","# -------------------------\n","# Build FRIENDS index\n","# -------------------------\n","friends_index = AnnoyIndex(dim, 'angular')\n","friends_map = {}\n","\n","for idx, row in enumerate(friends_pd.itertuples()):\n","    friends_index.add_item(idx, np.array(row.vector, dtype=\"float32\"))\n","    friends_map[idx] = row.spotify_id\n","\n","friends_index.build(20)\n","friends_index.save(f\"{ANNOY_DIR}/friends_index.ann\")\n","joblib.dump(friends_map, f\"{ANNOY_DIR}/friends_map.pkl\")\n","\n","# -------------------------\n","# Build OCEAN index\n","# -------------------------\n","ocean_index = AnnoyIndex(dim, 'angular')\n","ocean_map = {}\n","\n","for idx, row in enumerate(ocean_pd.itertuples()):\n","    ocean_index.add_item(idx, np.array(row.vector, dtype=\"float32\"))\n","    ocean_map[idx] = row.spotify_id\n","\n","ocean_index.build(20)\n","ocean_index.save(f\"{ANNOY_DIR}/ocean_index.ann\")\n","joblib.dump(ocean_map, f\"{ANNOY_DIR}/ocean_map.pkl\")\n","\n","print(\"âœ… Annoy indices saved to /lakehouse/default/Files/annoy/\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","normalized_state":"finished","queued_time":"2025-11-25T06:50:23.130189Z","session_start_time":null,"execution_start_time":"2025-11-25T06:50:23.1313173Z","execution_finish_time":"2025-11-25T06:51:58.8918701Z","parent_msg_id":"f179e550-1d34-44ee-898c-479e28886687"},"text/plain":"StatementMeta(, bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa, 16, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Annoy indices saved to /lakehouse/default/Files/annoy/\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"99fa68f0-568f-40ec-9a13-61b0b23aa1a8\",\"activityId\":\"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa\",\"applicationId\":\"application_1764052280263_0001\",\"jobGroupId\":\"16\",\"advices\":{\"warn\":2}}"}},"id":"644fb18a-c113-4ed2-bdff-1c0e8e783256"},{"cell_type":"code","source":["# ============================================\n","# CELL 8 â€” TRAIN LIGHTGBM RE-RANKER (HARD NEGATIVES)\n","# ============================================\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from collections import defaultdict\n","from annoy import AnnoyIndex\n","from datetime import datetime\n","import numpy as np\n","import joblib\n","import os\n","import lightgbm as lgb\n","\n","# ------------------------------------------------\n","# CONFIG\n","# ------------------------------------------------\n","TRAIN_USER_LIMIT = 3000    # how many users to sample for training\n","K_PER_USER       = 200     # how many neighbors per user\n","\n","print(\"âš™ï¸ Training LightGBM with HARD negatives\")\n","print(f\"   Users sampled: {TRAIN_USER_LIMIT}, K per user: {K_PER_USER}\")\n","\n","# ------------------------------------------------\n","# 1) Load user embeddings (only users we have vectors for)\n","# ------------------------------------------------\n","user_emb_spark = spark.table(USER_EMB_TABLE)   # spotify_user_id, vector\n","gold_users = spark.table(GOLD_LABEL_TABLE).select(\"spotify_user_id\").distinct()\n","\n","train_users_spark = (\n","    gold_users.join(user_emb_spark, \"spotify_user_id\", \"inner\")\n","              .limit(TRAIN_USER_LIMIT)\n",")\n","\n","train_users_pd = train_users_spark.toPandas()\n","print(f\"ðŸ‘¥ Training users with embeddings: {len(train_users_pd):,}\")\n","\n","if train_users_pd.empty:\n","    raise Exception(\"No users with embeddings found for training.\")\n","\n","# ------------------------------------------------\n","# 2) Load item embeddings + build Annoy index\n","# ------------------------------------------------\n","item_emb_spark = spark.table(ITEM_EMB_TABLE).select(\"spotify_id\", \"vector\")\n","item_pd = item_emb_spark.toPandas()\n","\n","print(f\"ðŸŽµ Items with embeddings: {len(item_pd):,}\")\n","\n","dim = len(item_pd.iloc[0].vector)\n","ann = AnnoyIndex(dim, 'angular')\n","\n","for idx, row in enumerate(item_pd.itertuples()):\n","    ann.add_item(idx, np.array(row.vector, dtype=\"float32\"))\n","\n","print(\"âš™ï¸ Building Annoy index for items...\")\n","ann.build(20)\n","print(\"âœ… Annoy index built.\")\n","\n","# ------------------------------------------------\n","# 3) Build positive map: which tracks each user actually played\n","# ------------------------------------------------\n","pos_pd = (\n","    spark.table(GOLD_LABEL_TABLE)\n","         .select(\"spotify_user_id\", \"spotify_id\")\n","         .distinct()\n","         .toPandas()\n",")\n","\n","pos_map = defaultdict(set)\n","for row in pos_pd.itertuples():\n","    pos_map[row.spotify_user_id].add(row.spotify_id)\n","\n","print(f\"ðŸ“¦ Positive interactions (rows): {len(pos_pd):,}\")\n","\n","# ------------------------------------------------\n","# 4) Generate (user, item, label) pairs from ANN neighbors\n","# ------------------------------------------------\n","training_rows = []  # (spotify_user_id, spotify_id, label)\n","\n","for u in train_users_pd.itertuples():\n","    u_id = u.spotify_user_id\n","    u_vec = np.array(u.vector, dtype=\"float32\")\n","\n","    # get ANN neighbors for this user\n","    idxs = ann.get_nns_by_vector(u_vec, K_PER_USER)\n","\n","    user_pos_set = pos_map[u_id]\n","\n","    for idx in idxs:\n","        sid = item_pd.iloc[idx].spotify_id\n","        label = 1 if sid in user_pos_set else 0\n","        training_rows.append((u_id, sid, int(label)))\n","\n","print(f\"ðŸ§± Generated training pairs: {len(training_rows):,}\")\n","\n","if not training_rows:\n","    raise Exception(\"No training pairs generated. Check your embeddings and GOLD_LABEL_TABLE.\")\n","\n","# ------------------------------------------------\n","# 5) Convert to Spark and join audio features\n","# ------------------------------------------------\n","training_spark = spark.createDataFrame(\n","    training_rows,\n","    [\"spotify_user_id\", \"spotify_id\", \"label\"]\n",")\n","\n","catalog = spark.table(CATALOG_TABLE).select(\"spotify_id\", *AUDIO_FEATURES)\n","\n","train_joined = (\n","    training_spark.join(catalog, \"spotify_id\", \"inner\")\n",")\n","\n","print(f\"ðŸ“¦ Train rows after joining audio features: {train_joined.count():,}\")\n","\n","# ------------------------------------------------\n","# 6) Spark â†’ Pandas â†’ LightGBM\n","# ------------------------------------------------\n","pdf = train_joined.select(AUDIO_FEATURES + [\"label\"]).toPandas()\n","\n","X = pdf[AUDIO_FEATURES].values.astype(\"float32\")\n","y = pdf[\"label\"].values.astype(\"int32\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(f\"ðŸ§ª Train size: {len(X_train):,}, Test size: {len(X_test):,}\")\n","\n","# ------------------------------------------------\n","# 7) Train LightGBM (Fabric-safe: no kwargs in fit)\n","# ------------------------------------------------\n","model_lgb = lgb.LGBMClassifier(\n","    objective=\"binary\",\n","    learning_rate=0.05,\n","    num_leaves=63,\n","    n_estimators=300,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    reg_lambda=0.1,\n","    reg_alpha=0.0,\n",")\n","\n","print(\"ðŸš€ Training LightGBM re-ranker (hard negatives)...\")\n","model_lgb.fit(X_train, y_train)\n","\n","# ------------------------------------------------\n","# 8) Evaluate\n","# ------------------------------------------------\n","y_prob = model_lgb.predict_proba(X_test)[:, 1]\n","y_pred = (y_prob >= 0.5).astype(int)\n","\n","auc = roc_auc_score(y_test, y_prob)\n","acc = accuracy_score(y_test, y_pred)\n","\n","print(f\"\\nðŸŽ¯ LightGBM Accuracy (hard negatives): {acc*100:.2f}%\")\n","print(f\"ðŸ“ˆ LightGBM ROC AUC (hard negatives):  {auc:.3f}\")\n","\n","# ------------------------------------------------\n","# 9) Save model  (FABRIC-SAFE)\n","# ------------------------------------------------\n","\n","MODEL_DIR = \"/lakehouse/default/Files/models\"\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","\n","LGBM_MODEL_PATH = f\"{MODEL_DIR}/lgbm_re_ranker.pkl\"\n","joblib.dump(model_lgb, LGBM_MODEL_PATH)\n","\n","print(f\"ðŸ’¾ LightGBM model saved to: {LGBM_MODEL_PATH}\")\n","\n","MODEL_VERSION = f\"lgbm_v_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n","MODEL_TRAINED_AT = datetime.now().isoformat()\n","\n","print(\"ðŸ“Œ MODEL VERSION:\", MODEL_VERSION)\n","print(\"ðŸ“Œ TRAINED AT:\", MODEL_TRAINED_AT)\n","\n","# Save metadata into delta table\n","metadata_df = spark.createDataFrame(\n","    [(MODEL_VERSION, MODEL_TRAINED_AT)],\n","    [\"model_version\", \"trained_at\"]\n",")\n","\n","metadata_df.write.mode(\"overwrite\").saveAsTable(\"gold_model_metadata\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","normalized_state":"finished","queued_time":"2025-11-25T06:45:03.9078605Z","session_start_time":null,"execution_start_time":"2025-11-25T06:45:03.9092709Z","execution_finish_time":"2025-11-25T06:48:26.0088005Z","parent_msg_id":"665fc75e-4f25-4ce0-99a0-41a1b4991f5c"},"text/plain":"StatementMeta(, bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âš™ï¸ Training LightGBM with HARD negatives\n   Users sampled: 3000, K per user: 200\nðŸ‘¥ Training users with embeddings: 27\nðŸŽµ Items with embeddings: 1,239,363\nâš™ï¸ Building Annoy index for items...\nâœ… Annoy index built.\nðŸ“¦ Positive interactions (rows): 31,107\nðŸ§± Generated training pairs: 5,400\nðŸ“¦ Train rows after joining audio features: 7,521\nðŸ§ª Train size: 6,016, Test size: 1,505\nðŸš€ Training LightGBM re-ranker (hard negatives)...\n[LightGBM] [Info] Number of positive: 1401, number of negative: 4615\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022528 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2304\n[LightGBM] [Info] Number of data points in the train set: 6016, number of used features: 11\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.232879 -> initscore=-1.192126\n[LightGBM] [Info] Start training from score -1.192126\n"]},{"output_type":"display_data","data":{"application/vnd.mlflow.run-widget+json":{"info":{"artifact_uri":"sds://onelakewesteurope.pbidedicated.windows.net/93da16a5-3c33-440e-bbec-66866bce621b/356d82df-4df6-4e33-a9ae-77978bf83b65/Data/d5b1b80a-b411-485b-a4e9-162f955482d9/artifacts","end_time":1764053277,"experiment_id":"356d82df-4df6-4e33-a9ae-77978bf83b65","lifecycle_stage":"active","run_id":"d5b1b80a-b411-485b-a4e9-162f955482d9","run_name":"amusing_nerve_q33k79nm","run_uuid":"d5b1b80a-b411-485b-a4e9-162f955482d9","start_time":1764053263,"status":"FINISHED","user_id":"trusted-service-user"},"data":{"metrics":{},"params":{"boosting_type":"gbdt","categorical_feature":"auto","colsample_bytree":"0.8","feature_name":"auto","keep_training_booster":"False","learning_rate":"0.05","max_depth":"-1","metric":"['binary']","min_child_samples":"20","min_child_weight":"0.001","min_split_gain":"0.0","num_boost_round":"300","num_leaves":"63","num_threads":"4","objective":"binary","random_state":"None","reg_alpha":"0.0","reg_lambda":"0.1","subsample":"0.8","subsample_for_bin":"200000","subsample_freq":"0"},"tags":{"mlflow.autologging":"lightgbm","mlflow.runName":"amusing_nerve_q33k79nm","mlflow.source.name":"/home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages/ipykernel_launcher.py","mlflow.source.type":"LOCAL","mlflow.user":"trusted-service-user","synapseml.livy.id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","synapseml.notebook.artifactId":"99fa68f0-568f-40ec-9a13-61b0b23aa1a8","synapseml.run.artifactJobId":"4776c76b-5942-4b61-b0db-050eab2461e4","synapseml.user.id":"ad43022d-87c5-4518-8a1b-94f6ab080ad4","synapseml.user.name":"Younis","synapseml.experimentName":"Gold_ML_Training","synapseml.experiment.artifactId":"356d82df-4df6-4e33-a9ae-77978bf83b65"}},"inputs":{"dataset_inputs":[]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nðŸŽ¯ LightGBM Accuracy (hard negatives): 81.99%\nðŸ“ˆ LightGBM ROC AUC (hard negatives):  0.792\nðŸ’¾ LightGBM model saved to: /lakehouse/default/Files/models/lgbm_re_ranker.pkl\nðŸ“Œ MODEL VERSION: lgbm_v_20251125_0647\nðŸ“Œ TRAINED AT: 2025-11-25T06:47:58.734444\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"99fa68f0-568f-40ec-9a13-61b0b23aa1a8\",\"activityId\":\"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa\",\"applicationId\":\"application_1764052280263_0001\",\"jobGroupId\":\"14\",\"advices\":{\"warn\":3}}"}},"id":"b3ead612-d044-49cf-bec3-62964e6b8bf0"},{"cell_type":"code","source":["import os\n","\n","print(os.path.exists(\"/lakehouse/default/Files/models/lgbm_re_ranker.pkl\"))\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa","normalized_state":"finished","queued_time":"2025-11-25T06:48:27.3408036Z","session_start_time":null,"execution_start_time":"2025-11-25T06:48:27.3419752Z","execution_finish_time":"2025-11-25T06:48:27.7450925Z","parent_msg_id":"53d3fea3-ea96-47e9-8092-92c7b4701c05"},"text/plain":"StatementMeta(, bc2c5a25-4507-4d1f-8c83-7c0b0ffd88fa, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["True\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"720f4079-53dd-4c88-a460-553cb5fa9c05"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2"}],"default_lakehouse":"e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2","default_lakehouse_name":"sonic_lakehouse","default_lakehouse_workspace_id":"93da16a5-3c33-440e-bbec-66866bce621b"}}},"nbformat":4,"nbformat_minor":5}