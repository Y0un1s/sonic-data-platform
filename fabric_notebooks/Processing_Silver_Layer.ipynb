{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 0 - Imports & Globals\n",
    "# Purpose: centralize imports, constants, and small helper functions used across cells.\n",
    "# ==================================================================\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, input_file_name, regexp_extract, current_timestamp, row_number,\n",
    "    explode, posexplode, expr, split, element_at\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# ---- Global paths (adjust when running) ----\n",
    "BRONZE_BASE = \"Files/bronze/spotify\"\n",
    "SILVER_BASE = \"Files/silver/spotify\"\n",
    "\n",
    "# ---- Helper: safe write as Delta table (upsert shortcut for simple inserts) ----\n",
    "def upsert_into_delta(table_name: str, df: DataFrame, match_condition: str, update_on_match: bool = False):\n",
    "    \"\"\"\n",
    "    Upsert (merge) df into existing Delta table by match_condition.\n",
    "    If table does not exist, this will raise â€” run CREATE TABLE first (see DDL cells).\n",
    "    Set update_on_match=True if you want to update matched rows as well.\n",
    "    \"\"\"\n",
    "    delta = DeltaTable.forName(spark, table_name)\n",
    "    m = delta.alias('t').merge(df.alias('s'), match_condition)\n",
    "    if update_on_match:\n",
    "        m = m.whenMatchedUpdateAll()\n",
    "    m.whenNotMatchedInsertAll().execute()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 15,
       "statement_ids": [
        15
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:39:37.6368225Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:39:52.4227665Z",
       "execution_finish_time": "2025-12-09T18:39:52.8038659Z",
       "parent_msg_id": "453c53a6-9641-426f-bfc3-e7fd506c844d"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 15, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 13,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "28d2ce1a-ca53-47ca-b330-dbf2571c54bd"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 1 - SQL DDL: Create Silver Schemas (single place for table definitions)\n",
    "# Purpose: define explicit schemas for main silver tables using SQL DDL.\n",
    "# Run this once before merges. Keeps schema definitions readable and versionable.\n",
    "# ==================================================================\n",
    "# NOTE: We keep DDLs compact here. Modify types/props as needed.\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_followed_artists (\n",
    "    spotify_user_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    artist_genres ARRAY<STRING>,\n",
    "    artist_popularity INT,\n",
    "    artist_followers INT,\n",
    "    artist_uri STRING,\n",
    "    artist_image_url STRING\n",
    ")\n",
    "USING delta\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_saved_tracks (\n",
    "    spotify_user_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    added_at STRING,\n",
    "    track_id STRING,\n",
    "    track_name STRING,\n",
    "    duration_ms INT,\n",
    "    explicit BOOLEAN,\n",
    "    popularity INT,\n",
    "\n",
    "    spotify_url STRING,\n",
    "    track_uri STRING,\n",
    "    track_number INT,\n",
    "    disc_number INT,\n",
    "\n",
    "    album_id STRING,\n",
    "    album_name STRING,\n",
    "    album_type STRING,\n",
    "    release_date STRING,\n",
    "    total_tracks INT,\n",
    "    album_image_url STRING,\n",
    "\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    artist_type STRING,\n",
    "    artist_url STRING\n",
    ")\n",
    "USING delta\n",
    "TBLPROPERTIES (\n",
    "    delta.autoOptimize.optimizeWrite = true,\n",
    "    delta.autoOptimize.autoCompact = true\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_recently_played (\n",
    "    spotify_user_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    played_at TIMESTAMP,\n",
    "    track_id STRING,\n",
    "    track_name STRING,\n",
    "    popularity INT,\n",
    "    duration_ms INT,\n",
    "    explicit BOOLEAN,\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    album_id STRING,\n",
    "    album_name STRING,\n",
    "    album_image_url STRING,\n",
    "    context_type STRING,\n",
    "    context_uri STRING\n",
    ")\n",
    "USING delta\n",
    "TBLPROPERTIES (\n",
    "    delta.autoOptimize.optimizeWrite = true,\n",
    "    delta.autoOptimize.autoCompact = true\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_top_tracks (\n",
    "    spotify_user_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    time_range STRING,\n",
    "    rank INT,\n",
    "    track_id STRING,\n",
    "    track_name STRING,\n",
    "    popularity INT,\n",
    "    duration_ms INT,\n",
    "    explicit BOOLEAN,\n",
    "    track_number INT,\n",
    "    external_url STRING,\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    album_id STRING,\n",
    "    album_name STRING,\n",
    "    release_date STRING,\n",
    "    album_image_url STRING\n",
    ")\n",
    "USING delta\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_top_artists (\n",
    "    spotify_user_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    time_range STRING,\n",
    "    rank INT,\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    popularity INT,\n",
    "    followers INT,\n",
    "    artist_genres ARRAY<STRING>,\n",
    "    external_url STRING,\n",
    "    artist_image_url STRING\n",
    ")\n",
    "USING delta\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS silver_playlist_tracks (\n",
    "    spotify_user_id STRING,\n",
    "    playlist_id STRING,\n",
    "    snapshot_date DATE,\n",
    "    position INT,\n",
    "    added_at TIMESTAMP,\n",
    "    added_by_id STRING,\n",
    "    track_id STRING,\n",
    "    track_name STRING,\n",
    "    popularity INT,\n",
    "    duration_ms INT,\n",
    "    explicit BOOLEAN,\n",
    "    external_url STRING,\n",
    "    artist_id STRING,\n",
    "    artist_name STRING,\n",
    "    album_id STRING,\n",
    "    album_name STRING,\n",
    "    album_image_url STRING\n",
    ")\n",
    "USING delta\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 16,
       "statement_ids": [
        16
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:39:37.7353981Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:39:52.8063254Z",
       "execution_finish_time": "2025-12-09T18:39:55.5194792Z",
       "parent_msg_id": "70b90903-349c-4cc5-a18e-1fd28b661e10"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 16, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 47,
     "data": {
      "text/plain": "DataFrame[]"
     },
     "metadata": {}
    }
   ],
   "execution_count": 14,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "6861dd34-01e1-4042-b8b5-1fcf18f57c90"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 2 - Standardized: Load raw JSON files (pattern-based loader)\n",
    "# Purpose: single reusable approach to read JSON with source path column\n",
    "# Usage: pass source_path (glob) and the regex path_pattern to extract metadata\n",
    "# ==================================================================\n",
    "\n",
    "def load_json_with_path(source_path: str) -> DataFrame:\n",
    "    \"\"\"Read multiline JSONs and add a source_path column for metadata extraction.\"\"\"\n",
    "    return (\n",
    "        spark.read\n",
    "             .option(\"multiline\", True)\n",
    "             .json(source_path)\n",
    "             .withColumn(\"source_path\", input_file_name())\n",
    "    )\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 17,
       "statement_ids": [
        17
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:39:37.9428254Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:39:55.5215789Z",
       "execution_finish_time": "2025-12-09T18:39:55.9600808Z",
       "parent_msg_id": "7868c288-c0ed-48be-a36e-2466611165da"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 17, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 15,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "6b6ee2dd-9f08-436c-895b-2c9f1fc969d2"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 3 - USER PROFILE: Latest snapshot per user (Dimension)\n",
    "# Purpose: keep one latest profile record per spotify_user_id\n",
    "# Steps grouped: load -> extract snapshot_date -> window latest -> flatten -> write\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/user_profile/*/data.json\"\n",
    "path_pattern = r\".*/spotify/[^/]+/user_profile/([^/]+)/data\\.json$\"\n",
    "\n",
    "df_raw = load_json_with_path(source_path)\n",
    "\n",
    "# Extract snapshot_date and cast to date\n",
    "df = df_raw.withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 1).cast(\"date\"))\n",
    "\n",
    "# Keep latest snapshot per user using window\n",
    "w = Window.partitionBy(\"ingestion_metadata.spotify_user_id\").orderBy(col(\"snapshot_date\").desc())\n",
    "\n",
    "df_latest = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "# Flatten only required fields and add ingestion timestamp\n",
    "df_user_profile = (\n",
    "    df_latest.select(\n",
    "        col(\"ingestion_metadata.spotify_user_id\").alias(\"spotify_user_id\"),\n",
    "        col(\"snapshot_date\"),\n",
    "        col(\"ingestion_metadata.run_utc\").alias(\"run_utc\"),\n",
    "        col(\"payload.display_name\").alias(\"display_name\"),\n",
    "        col(\"payload.email\").alias(\"email\"),\n",
    "        col(\"payload.country\").alias(\"country\"),\n",
    "        col(\"payload.product\").alias(\"subscription_type\"),\n",
    "        col(\"payload.followers.total\").alias(\"follower_count\"),\n",
    "        col(\"payload.explicit_content.filter_enabled\").alias(\"explicit_filter_enabled\"),\n",
    "        col(\"payload.explicit_content.filter_locked\").alias(\"explicit_filter_locked\"),\n",
    "        col(\"payload.uri\").alias(\"spotify_uri\"),\n",
    "        col(\"payload.images\").alias(\"images\"),\n",
    "        current_timestamp().alias(\"ingested_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Overwrite the silver_user_profile table (dimension - latest snapshot)\n",
    "df_user_profile.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_user_profile\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 18,
       "statement_ids": [
        18
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:39:38.048574Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:39:55.9619299Z",
       "execution_finish_time": "2025-12-09T18:40:51.6317288Z",
       "parent_msg_id": "f0637ef0-7731-4640-9314-31f5bd4c3dac"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 18, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "a3c7fd3e-f301-42d7-9366-0c94ea437e06"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 4 - FOLLOWED ARTISTS: flatten and insert new follows\n",
    "# Purpose: flatten followed artists snapshots and insert only new (per user+artist)\n",
    "# Steps grouped: load -> extract snapshot_date -> explode items -> clean -> dedupe -> merge\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/followed_artists/*/data.json\"\n",
    "path_pattern = r\".*/spotify/[^/]+/followed_artists/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "raw = raw.withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 1).cast(\"date\"))\n",
    "\n",
    "exploded = raw.select(\n",
    "    col(\"ingestion_metadata.spotify_user_id\").alias(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    explode(col(\"payload.artists.items\")).alias(\"artist\")\n",
    ")\n",
    "\n",
    "clean = exploded.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"artist.id\").alias(\"artist_id\"),\n",
    "    col(\"artist.name\").alias(\"artist_name\"),\n",
    "    col(\"artist.genres\").alias(\"artist_genres\"),\n",
    "    col(\"artist.popularity\").alias(\"artist_popularity\"),\n",
    "    col(\"artist.followers.total\").alias(\"artist_followers\"),\n",
    "    col(\"artist.uri\").alias(\"artist_uri\"),\n",
    "    expr(\"artist.images[0].url\").alias(\"artist_image_url\")\n",
    ").dropDuplicates([\"spotify_user_id\", \"artist_id\"])  # dedupe within batch\n",
    "\n",
    "# Merge inserts only new artists per user\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_followed_artists\",\n",
    "    df=clean,\n",
    "    match_condition=\"t.spotify_user_id = s.spotify_user_id AND t.artist_id = s.artist_id\",\n",
    "    update_on_match=False\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 19,
       "statement_ids": [
        19
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:39:38.2226294Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:40:51.6340724Z",
       "execution_finish_time": "2025-12-09T18:41:12.7613545Z",
       "parent_msg_id": "1a1280e0-e56c-46b2-b4f2-e3477551b50d"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 19, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 17,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "93885ff7-67ff-4b35-a217-7686b91cd1c8"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 5 - SAVED TRACKS: flatten multi-page payloads and merge\n",
    "# Purpose: transform user's saved tracks and ensure one row per (user, track)\n",
    "# Steps grouped: load -> extract snapshot_date -> explode pages -> flatten -> dedupe -> merge\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/saved_tracks/*/data.json\"\n",
    "path_pattern = r\".*/spotify/[^/]+/saved_tracks/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "raw = raw.withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 1).cast(\"date\"))\n",
    "\n",
    "# payload is array of pages -> explode pages then items\n",
    "df_items = raw.select(\n",
    "    col(\"ingestion_metadata.spotify_user_id\").alias(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    explode(col(\"payload\")).alias(\"entry\")\n",
    ").select(\n",
    "    \"spotify_user_id\",\n",
    "    \"snapshot_date\",\n",
    "    explode(col(\"entry.items\")).alias(\"item\")\n",
    ")\n",
    "\n",
    "# flatten\n",
    "clean = df_items.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"item.added_at\").alias(\"added_at\"),\n",
    "    col(\"item.track.id\").alias(\"track_id\"),\n",
    "    col(\"item.track.name\").alias(\"track_name\"),\n",
    "    col(\"item.track.duration_ms\"),\n",
    "    col(\"item.track.explicit\"),\n",
    "    col(\"item.track.popularity\"),\n",
    "    col(\"item.track.external_urls.spotify\").alias(\"spotify_url\"),\n",
    "    col(\"item.track.uri\").alias(\"track_uri\"),\n",
    "    col(\"item.track.track_number\"),\n",
    "    col(\"item.track.disc_number\"),\n",
    "    col(\"item.track.album.id\").alias(\"album_id\"),\n",
    "    col(\"item.track.album.name\").alias(\"album_name\"),\n",
    "    col(\"item.track.album.album_type\"),\n",
    "    col(\"item.track.album.release_date\").alias(\"release_date\"),\n",
    "    col(\"item.track.album.total_tracks\"),\n",
    "    expr(\"item.track.album.images[0].url\").alias(\"album_image_url\"),\n",
    "    expr(\"item.track.artists[0].id\").alias(\"artist_id\"),\n",
    "    expr(\"item.track.artists[0].name\").alias(\"artist_name\"),\n",
    "    expr(\"item.track.artists[0].type\").alias(\"artist_type\"),\n",
    "    expr(\"item.track.artists[0].external_urls.spotify\").alias(\"artist_url\")\n",
    ")\n",
    "\n",
    "# dedupe source batch\n",
    "df_final_source = clean.dropDuplicates([\"spotify_user_id\", \"track_id\"])\n",
    "\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_saved_tracks\",\n",
    "    df=df_final_source,\n",
    "    match_condition=\"t.spotify_user_id = s.spotify_user_id AND t.track_id = s.track_id\",\n",
    "    update_on_match=False\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 21,
       "statement_ids": [
        21
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:43:19.7376814Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:43:19.7388262Z",
       "execution_finish_time": "2025-12-09T18:43:38.8780086Z",
       "parent_msg_id": "e84a44de-7663-403b-b97a-460a4488036e"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 21, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 19,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "4a168fee-1ddc-42db-9ec2-ff9f831990fc"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 6 - RECENTLY PLAYED: flatten and merge play events (append-heavy)\n",
    "# Purpose: ingest play events with played_at as event timestamp (PK per user + played_at)\n",
    "# Steps grouped: load -> extract snapshot_date -> explode payload[0].items -> flatten -> dedupe -> merge\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/recently_played/*/data.json\"\n",
    "path_pattern = r\".*/spotify/[^/]+/recently_played/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "raw = raw.withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 1).cast(\"date\"))\n",
    "\n",
    "exploded = raw.select(\n",
    "    col(\"ingestion_metadata.spotify_user_id\").alias(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    explode(col(\"payload\")[0].items).alias(\"item\")\n",
    ")\n",
    "\n",
    "clean = exploded.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"item.played_at\").cast(\"timestamp\").alias(\"played_at\"),\n",
    "    col(\"item.track.id\").alias(\"track_id\"),\n",
    "    col(\"item.track.name\").alias(\"track_name\"),\n",
    "    col(\"item.track.popularity\"),\n",
    "    col(\"item.track.duration_ms\"),\n",
    "    col(\"item.track.explicit\"),\n",
    "    expr(\"item.track.artists[0].id\").alias(\"artist_id\"),\n",
    "    expr(\"item.track.artists[0].name\").alias(\"artist_name\"),\n",
    "    col(\"item.track.album.id\").alias(\"album_id\"),\n",
    "    col(\"item.track.album.name\").alias(\"album_name\"),\n",
    "    expr(\"item.track.album.images[0].url\").alias(\"album_image_url\"),\n",
    "    col(\"item.context.type\").alias(\"context_type\"),\n",
    "    col(\"item.context.uri\").alias(\"context_uri\")\n",
    ")\n",
    "\n",
    "# dedupe by event key\n",
    "df_final_source = clean.dropDuplicates([\"spotify_user_id\", \"played_at\"])\n",
    "\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_recently_played\",\n",
    "    df=df_final_source,\n",
    "    match_condition=\"t.spotify_user_id = s.spotify_user_id AND t.played_at = s.played_at\",\n",
    "    update_on_match=False\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 22,
       "statement_ids": [
        22
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:43:43.7508321Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:43:43.7520135Z",
       "execution_finish_time": "2025-12-09T18:44:09.5139297Z",
       "parent_msg_id": "1d56922c-7bd2-43cc-9525-fa4d5cd4db0a"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 22, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 20,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "4fef29a4-60db-433d-a85f-1d1ab5a0e348"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 7 - TOP TRACKS: parse time range and rank using posexplode\n",
    "# Purpose: capture ordered top tracks per user/time_range/snapshot\n",
    "# Steps grouped: load -> extract user/time_range/snapshot -> posexplode -> flatten -> dedupe -> merge\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/top_tracks_*_term/*/data.json\"\n",
    "path_pattern = r\".*/spotify/([^/]+)/top_tracks_([^_]+)_term/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "\n",
    "# extract user id, time_range and snapshot (handles underscores in user folder)\n",
    "meta = raw.withColumn(\"spotify_user_id\", element_at(split(regexp_extract(\"source_path\", path_pattern, 1), \"_\"), -1)) \\\n",
    "          .withColumn(\"time_range\", regexp_extract(\"source_path\", path_pattern, 2)) \\\n",
    "          .withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 3).cast(\"date\"))\n",
    "\n",
    "exploded = meta.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"time_range\"),\n",
    "    posexplode(col(\"payload\")[0].items).alias(\"index\", \"item\")\n",
    ")\n",
    "\n",
    "clean = exploded.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"time_range\"),\n",
    "    (col(\"index\") + 1).alias(\"rank\"),\n",
    "    col(\"item.id\").alias(\"track_id\"),\n",
    "    col(\"item.name\").alias(\"track_name\"),\n",
    "    col(\"item.popularity\").cast(\"int\").alias(\"popularity\"),\n",
    "    col(\"item.duration_ms\"),\n",
    "    col(\"item.explicit\"),\n",
    "    col(\"item.track_number\"),\n",
    "    col(\"item.external_urls.spotify\").alias(\"external_url\"),\n",
    "    expr(\"item.artists[0].id\").alias(\"artist_id\"),\n",
    "    expr(\"item.artists[0].name\").alias(\"artist_name\"),\n",
    "    col(\"item.album.id\").alias(\"album_id\"),\n",
    "    col(\"item.album.name\").alias(\"album_name\"),\n",
    "    col(\"item.album.release_date\").alias(\"release_date\"),\n",
    "    expr(\"item.album.images[0].url\").alias(\"album_image_url\")\n",
    ")\n",
    "\n",
    "# dedupe within batch\n",
    "df_final = clean.dropDuplicates([\"spotify_user_id\", \"snapshot_date\", \"time_range\", \"rank\"])\n",
    "\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_top_tracks\",\n",
    "    df=df_final,\n",
    "    match_condition=(\n",
    "        \"t.spotify_user_id = s.spotify_user_id AND t.snapshot_date = s.snapshot_date \"\n",
    "        \"AND t.time_range = s.time_range AND t.rank = s.rank\"\n",
    "    ),\n",
    "    update_on_match=False\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 23,
       "statement_ids": [
        23
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:31.4800412Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:44:31.4811913Z",
       "execution_finish_time": "2025-12-09T18:45:29.1678311Z",
       "parent_msg_id": "ac1d452d-86b5-4feb-bf43-0c9c25a47571"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 23, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 21,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "5c567aed-6d8a-41bd-be50-7ef22dcfb703"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ==================================================================\n",
    "# CELL 8 - TOP ARTISTS: same pattern as top_tracks\n",
    "# Purpose: capture ordered top artists per user/time_range/snapshot\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/top_artists_*_term/*/data.json\"\n",
    "path_pattern = r\".*/spotify/([^/]+)/top_artists_([^_]+)_term/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "meta = raw.withColumn(\"spotify_user_id\", element_at(split(regexp_extract(\"source_path\", path_pattern, 1), \"_\"), -1)) \\\n",
    "          .withColumn(\"time_range\", regexp_extract(\"source_path\", path_pattern, 2)) \\\n",
    "          .withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 3).cast(\"date\"))\n",
    "\n",
    "exploded = meta.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"time_range\"),\n",
    "    posexplode(col(\"payload\")[0].items).alias(\"index\", \"item\")\n",
    ")\n",
    "\n",
    "clean = exploded.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    col(\"time_range\"),\n",
    "    (col(\"index\") + 1).alias(\"rank\"),\n",
    "    col(\"item.id\").alias(\"artist_id\"),\n",
    "    col(\"item.name\").alias(\"artist_name\"),\n",
    "    col(\"item.popularity\").cast(\"int\").alias(\"popularity\"),\n",
    "    col(\"item.followers.total\").cast(\"int\").alias(\"followers\"),\n",
    "    col(\"item.genres\").alias(\"artist_genres\"),\n",
    "    col(\"item.external_urls.spotify\").alias(\"external_url\"),\n",
    "    expr(\"item.images[0].url\").alias(\"artist_image_url\")\n",
    ")\n",
    "\n",
    "df_final = clean.dropDuplicates([\"spotify_user_id\", \"snapshot_date\", \"time_range\", \"rank\"])\n",
    "\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_top_artists\",\n",
    "    df=df_final,\n",
    "    match_condition=(\n",
    "        \"t.spotify_user_id = s.spotify_user_id AND t.snapshot_date = s.snapshot_date \"\n",
    "        \"AND t.time_range = s.time_range AND t.rank = s.rank\"\n",
    "    ),\n",
    "    update_on_match=False\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 24,
       "statement_ids": [
        24
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:33.7929712Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:45:29.170033Z",
       "execution_finish_time": "2025-12-09T18:46:44.6110104Z",
       "parent_msg_id": "fe5e97fb-3c83-43a5-844a-ad3647e14178"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 24, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 22,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "296d58f5-6ea7-4dd8-bbbf-d4247d406b06"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 9 - PLAYLIST TRACKS: capture playlist order and allow updates\n",
    "# Purpose: store playlist track order and metadata; update if track metadata changes\n",
    "# ==================================================================\n",
    "source_path = f\"{BRONZE_BASE}/*/playlist_*/*/data.json\"\n",
    "path_pattern = r\".*/spotify/([^/]+)/playlist_([^/]+)/([^/]+)/data\\.json$\"\n",
    "\n",
    "raw = load_json_with_path(source_path)\n",
    "meta = raw.withColumn(\"spotify_user_id\", element_at(split(regexp_extract(\"source_path\", path_pattern, 1), \"_\"), -1)) \\\n",
    "          .withColumn(\"playlist_id\", regexp_extract(\"source_path\", path_pattern, 2)) \\\n",
    "          .withColumn(\"snapshot_date\", regexp_extract(\"source_path\", path_pattern, 3).cast(\"date\"))\n",
    "\n",
    "exploded = meta.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"playlist_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    posexplode(col(\"payload\")[0].items).alias(\"index\", \"item\")\n",
    ")\n",
    "\n",
    "clean = exploded.select(\n",
    "    col(\"spotify_user_id\"),\n",
    "    col(\"playlist_id\"),\n",
    "    col(\"snapshot_date\"),\n",
    "    (col(\"index\") + 1).alias(\"position\"),\n",
    "    col(\"item.added_at\").cast(\"timestamp\").alias(\"added_at\"),\n",
    "    col(\"item.added_by.id\").alias(\"added_by_id\"),\n",
    "    col(\"item.track.id\").alias(\"track_id\"),\n",
    "    col(\"item.track.name\").alias(\"track_name\"),\n",
    "    col(\"item.track.popularity\").cast(\"int\").alias(\"popularity\"),\n",
    "    col(\"item.track.duration_ms\"),\n",
    "    col(\"item.track.explicit\"),\n",
    "    col(\"item.track.external_urls.spotify\").alias(\"external_url\"),\n",
    "    expr(\"item.track.artists[0].id\").alias(\"artist_id\"),\n",
    "    expr(\"item.track.artists[0].name\").alias(\"artist_name\"),\n",
    "    col(\"item.track.album.id\").alias(\"album_id\"),\n",
    "    col(\"item.track.album.name\").alias(\"album_name\"),\n",
    "    expr(\"item.track.album.images[0].url\").alias(\"album_image_url\")\n",
    ")\n",
    "\n",
    "# dedupe within batch and merge (update_on_match True to refresh metadata)\n",
    "df_final = clean.dropDuplicates([\"playlist_id\", \"track_id\"])\n",
    "\n",
    "upsert_into_delta(\n",
    "    table_name=\"silver_playlist_tracks\",\n",
    "    df=df_final,\n",
    "    match_condition=\"t.playlist_id = s.playlist_id AND t.track_id = s.track_id\",\n",
    "    update_on_match=True\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 25,
       "statement_ids": [
        25
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:37.4630175Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:46:44.6133055Z",
       "execution_finish_time": "2025-12-09T18:49:40.377995Z",
       "parent_msg_id": "8b226582-cd15-4e7f-bede-c4f8e5ff96a5"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 25, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 23,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false,
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"66de8539-14f7-4a66-8f15-f52fca76b2d1\",\"activityId\":\"82393ace-b2d5-47b8-864b-78b20106132e\",\"applicationId\":\"application_1765304037087_0001\",\"jobGroupId\":\"25\",\"advices\":{\"warn\":1}}"
    }
   },
   "id": "91d6cb4e-d508-44fd-b031-876bd251dcd0"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 10 - MASTER ARTISTS: build a master artists dimension (robust JSON handling)\n",
    "# Purpose: create/overwrite a master artist table from Files/silver/spotify/*/master_artists.json\n",
    "# Steps grouped: load -> normalize wrapper -> flatten -> dedupe -> overwrite table\n",
    "# ==================================================================\n",
    "source_path = f\"{SILVER_BASE}/*/master_artists.json\"\n",
    "try:\n",
    "    df_raw = spark.read.option(\"multiline\", True).json(source_path)\n",
    "except Exception as e:\n",
    "    print(f\"No master_artists.json found or empty. Error: {e}\")\n",
    "    dbutils.notebook.exit(\"No Data\")\n",
    "\n",
    "# normalize structure: either {\"artists\": [...]} or top-level array\n",
    "if \"artists\" in df_raw.columns:\n",
    "    df_flat = df_raw.select(explode(col(\"artists\")).alias(\"item\"))\n",
    "elif \"items\" in df_raw.columns:\n",
    "    df_flat = df_raw.select(explode(col(\"items\")).alias(\"item\"))\n",
    "else:\n",
    "    df_flat = df_raw.select(expr(\"struct(*)\").alias(\"item\"))\n",
    "\n",
    "# flatten and dedupe\n",
    "df_clean = df_flat.select(\n",
    "    col(\"item.id\").alias(\"artist_id\"),\n",
    "    col(\"item.name\").alias(\"artist_name\"),\n",
    "    col(\"item.popularity\").cast(\"int\").alias(\"popularity\"),\n",
    "    col(\"item.followers.total\").cast(\"int\").alias(\"followers\"),\n",
    "    col(\"item.genres\").alias(\"artist_genres\"),\n",
    "    col(\"item.external_urls.spotify\").alias(\"external_url\"),\n",
    "    expr(\"item.images[0].url\").alias(\"artist_image_url\")\n",
    ").dropDuplicates([\"artist_id\"])  # master by id\n",
    "\n",
    "# overwrite master table\n",
    "_df = df_clean\n",
    "_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_artists_raw\")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 26,
       "statement_ids": [
        26
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:39.7306442Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:49:40.3805483Z",
       "execution_finish_time": "2025-12-09T18:50:06.7111112Z",
       "parent_msg_id": "d859edb8-5149-49ae-9194-f85738be1100"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 26, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 24,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "68670a77-95ec-47f5-8cd8-a8dbd47bae63"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 11 - MASTER TRACKS: build master tracks (recco->spotify mapping)\n",
    "# Purpose: create/overwrite silver_tracks_raw from master_reccobeats_tracks.json\n",
    "# ==================================================================\n",
    "source_path = f\"{SILVER_BASE}/*/master_reccobeats_tracks.json\"\n",
    "try:\n",
    "    df_raw = spark.read.json(source_path)\n",
    "except Exception as e:\n",
    "    print(f\"No master_reccobeats_tracks.json found. Error: {e}\")\n",
    "    dbutils.notebook.exit(\"No Data\")\n",
    "\n",
    "# flatten minimal required fields\n",
    "df_clean = df_raw.select(\n",
    "    col(\"spotify_id\"),\n",
    "    col(\"recco_id\"),\n",
    "    col(\"trackTitle\").alias(\"track_name\"),\n",
    "    col(\"durationMs\").alias(\"duration_ms\"),\n",
    "    col(\"isrc\"),\n",
    "    col(\"popularity\"),\n",
    "    expr(\"artists[0].id\").alias(\"artist_recco_id\"),\n",
    "    expr(\"artists[0].name\").alias(\"artist_name\"),\n",
    "    col(\"href\").alias(\"api_link\")\n",
    ").dropDuplicates([\"spotify_id\"])\n",
    "\n",
    "# overwrite master table\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_tracks_raw\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 27,
       "statement_ids": [
        27
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:41.6760922Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:50:06.7133437Z",
       "execution_finish_time": "2025-12-09T18:50:37.418348Z",
       "parent_msg_id": "87973322-0698-41ac-8895-6a9dd9b91d19"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 27, Finished, Available, Finished)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 25,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "collapsed": false
   },
   "id": "822731d6-01dc-4888-9b47-0513a60531e0"
  },
  {
   "cell_type": "code",
   "source": [
    "# ==================================================================\n",
    "# CELL 12 - AUDIO FEATURES: join features -> spotify id and save\n",
    "# Purpose: combine audio feature records (recco_id) with spotify_id using master tracks file\n",
    "# ==================================================================\n",
    "source_path = f\"{SILVER_BASE}/*/master_reccobeats_features.json\"\n",
    "try:\n",
    "    df_features_raw = spark.read.json(source_path)\n",
    "except Exception as e:\n",
    "    print(\"No audio features found\")\n",
    "    dbutils.notebook.exit(\"No audio features found\")\n",
    "\n",
    "# prepare features\n",
    "df_features = df_features_raw.select(\n",
    "    col(\"id\").alias(\"recco_id\"),\n",
    "    col(\"danceability\"),\n",
    "    col(\"energy\"),\n",
    "    col(\"key\"),\n",
    "    col(\"loudness\"),\n",
    "    col(\"mode\"),\n",
    "    col(\"speechiness\"),\n",
    "    col(\"acousticness\"),\n",
    "    col(\"instrumentalness\"),\n",
    "    col(\"liveness\"),\n",
    "    col(\"valence\"),\n",
    "    col(\"tempo\")\n",
    ").dropDuplicates([\"recco_id\"])\n",
    "\n",
    "# load tracks mapping\n",
    "path_tracks = f\"{SILVER_BASE}/*/master_reccobeats_tracks.json\"\n",
    "df_tracks_raw = spark.read.json(path_tracks)\n",
    "df_lookup = df_tracks_raw.select(col(\"recco_id\"), col(\"spotify_id\")).dropDuplicates([\"recco_id\"])\n",
    "\n",
    "# join and save\n",
    "df_joined = df_features.join(df_lookup, on=\"recco_id\", how=\"inner\")\n",
    "\n",
    "df_final = df_joined.select(\n",
    "    col(\"spotify_id\"),\n",
    "    col(\"recco_id\"),\n",
    "    col(\"danceability\"),\n",
    "    col(\"energy\"),\n",
    "    col(\"key\"),\n",
    "    col(\"loudness\"),\n",
    "    col(\"mode\"),\n",
    "    col(\"speechiness\"),\n",
    "    col(\"acousticness\"),\n",
    "    col(\"instrumentalness\"),\n",
    "    col(\"liveness\"),\n",
    "    col(\"valence\"),\n",
    "    col(\"tempo\")\n",
    ")\n",
    "\n",
    "# overwrite or update as needed\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_audio_features_raw\")\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "spark_pool": null,
       "statement_id": 28,
       "statement_ids": [
        28
       ],
       "state": "finished",
       "livy_statement_state": "available",
       "session_id": "82393ace-b2d5-47b8-864b-78b20106132e",
       "normalized_state": "finished",
       "queued_time": "2025-12-09T18:44:43.8731022Z",
       "session_start_time": null,
       "execution_start_time": "2025-12-09T18:50:37.4207151Z",
       "execution_finish_time": "2025-12-09T18:51:04.4765432Z",
       "parent_msg_id": "e5a16aae-e22c-461e-995b-5ee61696972f"
      },
      "text/plain": "StatementMeta(, 82393ace-b2d5-47b8-864b-78b20106132e, 28, Finished, Available, Finished)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Refactored silver layer notebook cells completed.\n"
     ]
    }
   ],
   "execution_count": 26,
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "id": "fcde938b-e91b-49f7-a967-5d1f6ff4b071"
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "name": "synapse_pyspark",
   "display_name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "synapse_widget": {
   "version": "0.1",
   "state": {}
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "dependencies": {
   "lakehouse": {
    "known_lakehouses": [
     {
      "id": "e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2"
     }
    ],
    "default_lakehouse": "e9de4b82-79eb-4248-b4c5-bc19ae7fc9c2",
    "default_lakehouse_name": "sonic_lakehouse",
    "default_lakehouse_workspace_id": "93da16a5-3c33-440e-bbec-66866bce621b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
